:author: Yuan Tang
:email: terrytangyuan@gmail.com
:institution:
:corresponding:

:author: Hongliang Liu
:email: phunter.lau@gmail.com
:institution:
:equal-contributor:

------------------------------------------------

XGBoost: A Portable Distributed Gradient Boosting Library

------------------------------------------------

.. class:: abstract

   XGBoost is a distributed machine learning library under gradient boosting framework. It is designed and optimized for high efficiency, flexibility and portability. It provides a parallel tree boosting implementation (also known as GBDT or GBM) for solving many data science problems in a fast and accurate way. Beyond single machine parallelization, XGBoost also runs on major distributed environment such as Hadoop/YARN, Spark, and Flink, for distributed model training. More than half of the winning solutions in machine learning challenges hosted at Kaggle adopt XGBoost, and a wide range of use cases across industries. In this chapter, we will briefly introduce XGBoost, explain the meanings of selected important parameters, and the techniques for optimizing prediction using Python.

.. class:: keywords

   Gradient Boosting, Machine Learning, Predictive Analytics, Data Science


.. include:: papers/yuan_tang_hongliang_liu/intro.txt

.. include:: papers/yuan_tang_hongliang_liu/main_functionalities.txt

.. include:: papers/yuan_tang_hongliang_liu/parameter_explained.txt

.. include:: papers/yuan_tang_hongliang_liu/distributed_and_gpus.txt
